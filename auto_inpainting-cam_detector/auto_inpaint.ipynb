{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4803e83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf_keras_vis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m img_to_array\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf_act\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras_vis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalScore\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras_vis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradcam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gradcam\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras_vis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorecam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scorecam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras_vis'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt, cm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import (ResNet50,\n",
    "                                                    preprocess_input as resnet50_preprocess_input,\n",
    "                                                    decode_predictions as resnet50_decode_predictions)\n",
    "from tensorflow.keras.applications.vgg16 import (VGG16,\n",
    "                                                    preprocess_input as vgg16_preprocess_input,\n",
    "                                                    decode_predictions as vgg16_decode_predictions)\n",
    "from tensorflow.keras.applications.vgg19 import (VGG19,\n",
    "                                                    preprocess_input as vgg19_preprocess_input,\n",
    "                                                    decode_predictions as vgg19_decode_predictions)\n",
    "from tensorflow.keras.applications.inception_v3 import (InceptionV3,\n",
    "                                                    preprocess_input as inception_v3_preprocess_input,\n",
    "                                                    decode_predictions as inception_v3_decode_predictions)\n",
    "from tensorflow.keras.applications.xception import (Xception,\n",
    "                                                    preprocess_input as xception_preprocess_input,\n",
    "                                                    decode_predictions as xception_decode_predictions)\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "import tensorflow.keras.activations as tf_act\n",
    "\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.scorecam import Scorecam\n",
    "        \n",
    "from inpaint import inpaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "CURR_DIR = os.getcwd()\n",
    "\n",
    "def cnv_lst_arr(lst):\n",
    "    ''' Convert list object to array. '''\n",
    "    arr = np.array(lst)\n",
    "    return arr\n",
    "\n",
    "def reset_dir():\n",
    "    ''' Change the directory to root directory of project. '''\n",
    "    os.chdir(ROOT_DIR)\n",
    "    CURR_DIR = os.getcwd()\n",
    "\n",
    "def change_dir(dir):\n",
    "    '''\n",
    "    Change the directory to specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir: The directory where to set the cwd\n",
    "    '''\n",
    "    os.chdir(dir)\n",
    "    CURR_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde63b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class inpaint_defense:\n",
    "    def __init__(self, model=ResNet50(), activation_fn=tf_act.linear):\n",
    "        '''\n",
    "        Args:\n",
    "            model: The pre-trained model for making predictions\n",
    "            batch_size: The number of images in the dataset\n",
    "            classlabel: The class label for 1000 classes\n",
    "            clean_images: The batch of images without any adversarial patch [?, 224, 224, 3]\n",
    "            clean_predictions: The array of predictions for images without patch [?, class_index, class, confidence]\n",
    "            clean_class_lbls: The array of class index the clean image belongs to\n",
    "            ground_truths: The array of actual class the images belongs to \n",
    "            adv_images: The batch of adverasrial images [?, 224, 224, 3]\n",
    "            adv_predictions: The array of predictions for the adversarial image [?, class_index, object class, confidence]\n",
    "            adv_class_lbls: The index of each class the image with adversarial patch belongs to\n",
    "            new_predictions: The array of predictions after inpainting the adversarial image [?, class_index, object class, confidence]\n",
    "            new_class_lbls: The array of class index the inpainted image belongs to\n",
    "            cams: The batch of cam filter obtained for each image [?, 224, 224]\n",
    "            patch_mask: The patch mask generated using a threshold value (0.5) [?, 224, 224]\n",
    "            inpaint_images: The batch of images obtained after applying inpainting [?, 224, 224, 3]\n",
    "            Activation_fn: The activation function used for generating heatmap of salient features\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.batch_size = 0\n",
    "        self.clean_images = []\n",
    "        self.ground_truths = []\n",
    "        self.clean_class_lbls = []\n",
    "        self.adv_images = []\n",
    "        self.clean_predictions = []\n",
    "        self.adv_predictions = []\n",
    "        self.new_predictions = []\n",
    "        self.adv_class_lbls = []\n",
    "        self.new_class_lbls = []\n",
    "        self.cams = []\n",
    "        self.patch_masks = []\n",
    "        self.inpaint_images = []\n",
    "        self.activ_fn = activation_fn\n",
    "        \n",
    "        # Download the json file of list of classes in imagenet with index\n",
    "        if os.path.isfile('imagenet_class_index.json') == False:\n",
    "            os.system(\"wget \\\"https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json\\\"\")\n",
    "\n",
    "        CLASS_INDEX = json.load(open(\"imagenet_class_index.json\"))\n",
    "        \n",
    "        classlabel  = []\n",
    "        for i_dict in range(len(CLASS_INDEX)):\n",
    "            classlabel.append(CLASS_INDEX[str(i_dict)][1])\n",
    "        self.classlabel = classlabel\n",
    "        self.CLASS_INDEX = CLASS_INDEX\n",
    "\n",
    "    def load_dataset(self, directory, no_of_classes=100, img_per_class=2, show_plot=False):\n",
    "        '''\n",
    "        Load the dataset from given directory.\n",
    "\n",
    "        Args:\n",
    "            directory: A directory that contains folders in format:\n",
    "                                    ---directory\n",
    "                                        ---adv_images\n",
    "                                            ---class1\n",
    "                                                ---image1.jpg\n",
    "                                                ---image2.jpg\n",
    "                                                    ...\n",
    "                                            ---class2\n",
    "                                                ---image1.jpg\n",
    "                                                ---image2.jpg\n",
    "                                                    ...\n",
    "                                                ...\n",
    "                                        ---clean_images\n",
    "                                            ---class1\n",
    "                                                ---image1.jpg\n",
    "                                                ---image2.jpg\n",
    "                                                    ...\n",
    "                                            ---class2\n",
    "                                                ---image1.jpg\n",
    "                                                ---image2.jpg\n",
    "                                                    ...\n",
    "                                                ...\n",
    "                        Make sure the adversarial image folder start with 'adv' and clean image folder starts with 'clean'\n",
    "            img_per_class: The number of images to display for each class (defaults to 2)\n",
    "            show_plot: a boolean variable to determine whether to display the plots of images(default, True)\n",
    "        '''\n",
    "        clean_img_count = 0\n",
    "        adv_img_count = 0\n",
    "        try:\n",
    "            img_height = 224\n",
    "            img_width = 224\n",
    "            \n",
    "            change_dir(directory)\n",
    "            for folder in os.listdir():\n",
    "                data_directory = os.path.join(os.getcwd(), folder)\n",
    "                images = image_dataset_from_directory(\n",
    "                    data_directory,\n",
    "                    seed=42, \n",
    "                    image_size=(img_height, img_width),\n",
    "                    batch_size=img_per_class, # The dataset will yield individual samples.\n",
    "                    color_mode='rgb')\n",
    "\n",
    "                if folder.startswith('adv'):\n",
    "                    for img, labels in images.take(no_of_classes):\n",
    "                        [self.process_image(images, image, lbl, 'adv', show_plot) for image, lbl in zip(img, labels)]\n",
    "\n",
    "                if folder.startswith('clean'):\n",
    "                    for img, labels in images.take(no_of_classes):\n",
    "                        [self.process_image(images, image, lbl, 'clean', show_plot) for image, lbl in zip(img, labels)]\n",
    "            \n",
    "            if self.batch_size%2 == 0:\n",
    "                self.batch_size = int(self.batch_size/2)\n",
    "            # Convert all the list to array elements\n",
    "            self.clean_images = cnv_lst_arr(self.clean_images)\n",
    "            self.clean_predictions = cnv_lst_arr(self.clean_predictions)\n",
    "            self.clean_class_lbls = cnv_lst_arr(self.clean_class_lbls)\n",
    "            self.adv_images = cnv_lst_arr(self.adv_images)\n",
    "            self.adv_predictions = cnv_lst_arr(self.adv_predictions)\n",
    "            self.adv_class_lbls = cnv_lst_arr(self.adv_class_lbls)\n",
    "            self.ground_truths = cnv_lst_arr(self.ground_truths)\n",
    "            reset_dir()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(traceback.format_exc())\n",
    "            print(e)\n",
    "            reset_dir()\n",
    "    \n",
    "    def process_image(self, image_gen, image, label, data_type, plot=False):\n",
    "        \n",
    "        img = img_to_array(image).astype(np.uint8)\n",
    "        if data_type == 'adv':\n",
    "            self.adv_images.append(img.copy())\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "\n",
    "            preprocess_fn = self.preprocess_input_fn()\n",
    "            decode_fn = self.decode_predictionst_fn()\n",
    "\n",
    "            tmp_img = preprocess_fn(img.copy())\n",
    "            img_pred = self.model.predict(tmp_img)\n",
    "            prediction = decode_fn(img_pred, top=1)\n",
    "            class_lbl = self.classlabel.index(prediction[0][0][1])\n",
    "\n",
    "            self.adv_predictions.append(prediction[0][0])\n",
    "            self.adv_class_lbls.append(class_lbl)\n",
    "        else:\n",
    "            self.clean_images.append(img.copy())\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "\n",
    "            preprocess_fn = self.preprocess_input_fn()\n",
    "            decode_fn = self.decode_predictionst_fn()\n",
    "\n",
    "            tmp_img = preprocess_fn(img.copy())\n",
    "            img_pred = self.model.predict(tmp_img)\n",
    "            prediction = decode_fn(img_pred, top=1)\n",
    "            class_lbl = self.classlabel.index(prediction[0][0][1])\n",
    "\n",
    "            class_list = [itm for val in self.CLASS_INDEX.values() for itm in val]\n",
    "            ind = int(class_list.index(image_gen.class_names[label]) / 2)\n",
    "\n",
    "            self.ground_truths.append((self.classlabel[ind]))\n",
    "            self.clean_predictions.append(prediction[0][0])\n",
    "            self.clean_class_lbls.append(class_lbl)\n",
    "        self.batch_size += 1\n",
    "        if plot == True:\n",
    "            self.plot_images(img)\n",
    "\n",
    "    def preprocess_input_fn(self):\n",
    "        if self.model.name == 'resnet50':\n",
    "            return resnet50_preprocess_input\n",
    "        if self.model.name == 'vgg16':\n",
    "            return vgg16_preprocess_input\n",
    "        if self.model.name == 'vgg19':\n",
    "            return vgg19_preprocess_input\n",
    "        if self.model.name == 'inception_v3':\n",
    "            return inception_v3_preprocess_input\n",
    "        if self.model.name == 'xception':\n",
    "            return xception_preprocess_input\n",
    "        return None\n",
    "\n",
    "    def decode_predictionst_fn(self):\n",
    "        if self.model.name == 'resnet50':\n",
    "            return resnet50_decode_predictions\n",
    "        if self.model.name == 'vgg16':\n",
    "            return vgg16_decode_predictions\n",
    "        if self.model.name == 'vgg19':\n",
    "            return vgg19_decode_predictions\n",
    "        if self.model.name == 'inception_v3':\n",
    "            return rinception_v3_decode_predictions\n",
    "        if self.model.name == 'xception':\n",
    "            return xception_decode_predictions\n",
    "        return None\n",
    "\n",
    "\n",
    "    def grad_plot(self, cam, title, heatmap, index):\n",
    "        '''\n",
    "        Plot a graph of saliency feature generate through gradCAM.\n",
    "        \n",
    "        Args:\n",
    "            cam: The gradcam object which generates the heatmap\n",
    "            title: The title of the saliency plot\n",
    "            heatmap: The heatmap that we generated using gradcam object\n",
    "            index: The index of the saliency plot for respective image\n",
    "        '''\n",
    "        plt.title(title, fontsize=16)\n",
    "        plt.imshow(np.uint8(self.adv_images[index]))\n",
    "        plt.imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def apply_cam(self, mini_batch, step, show_plot=False):\n",
    "        '''\n",
    "        Generates the saliency map of the given batch of images using gradient CAM technique.\n",
    "\n",
    "        Args:\n",
    "            show_plot: a boolean variable to determine whether to display the saliency map for each image(default, True)\n",
    "        '''\n",
    "        # When the softmax activation function is applied to the last layer of model,\n",
    "        # it may obstruct generating the attention images, so you should replace the function to a linear activation function.\n",
    "\n",
    "        def model_modifier_function(cloned_model):\n",
    "            cloned_model.layers[-1].activation = self.activ_fn\n",
    "\n",
    "        # And then, you MUST create Score instance or define score function that returns target scores.\n",
    "        # Here, they return the score values corresponding to images.\n",
    "\n",
    "        score = CategoricalScore(self.adv_class_lbls[mini_batch : step].tolist())\n",
    "\n",
    "        image_titles = self.adv_predictions[mini_batch : step].copy()\n",
    "\n",
    "        # # Create Gradcam object\n",
    "        # gradcam = Gradcam(self.model, model_modifier=model_modifier_function, clone=True)\n",
    "        # # Generate heatmap with GradCAM\n",
    "        # cam = gradcam(score, (np.float32(self.adv_images)).copy(), penultimate_layer=-1)\n",
    "\n",
    "        # Create Scorecam object\n",
    "        scorecam = Scorecam(self.model, model_modifier=model_modifier_function)\n",
    "        # Generate heatmap with Faster-ScoreCAM\n",
    "        cam = scorecam(score, (np.float32(self.adv_images[mini_batch : step])).copy(), penultimate_layer=-1, max_N=10)\n",
    "\n",
    "        for i, title in enumerate(image_titles):\n",
    "            heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "\n",
    "            if show_plot == True:\n",
    "                self.grad_plot(cam, title, heatmap, i)\n",
    "\n",
    "            self.cams.append(cam[i].copy())\n",
    "\n",
    "    def mask_plot(self, img):\n",
    "        '''\n",
    "        Function that plots the mask generated for the image.\n",
    "\n",
    "        Args:\n",
    "            img: The mask image to print\n",
    "        '''\n",
    "        plt.imshow(np.uint8(img), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def gen_mask(self, show_plot=False):\n",
    "        ''' Generates a binary mask from saliency map obtained for every image in the given batch.'''\n",
    "\n",
    "        for ind in range(self.cams.shape[0]):\n",
    "\n",
    "            temp_cam = self.cams[ind].copy()        \n",
    "\n",
    "            binary_patch_mask = []\n",
    "            binary_patch_mask = np.where(temp_cam >= 0.5, 1., 0.) # 1. - (temp_cam.mean())\n",
    "\n",
    "            self.patch_masks.append(np.array(binary_patch_mask))\n",
    "\n",
    "            if show_plot == True:\n",
    "                self.mask_plot(binary_patch_mask)\n",
    "\n",
    "        self.patch_masks = cnv_lst_arr(self.patch_masks)\n",
    "\n",
    "    def apply_inpaint(self, show_plot=False):\n",
    "        '''\n",
    "        Applies inpainting technique toremove adversarial patch from the images in the given batch.\n",
    "        Also gives a plot of images obtained after inpainting along with class predictions\n",
    "\n",
    "        Args:\n",
    "            show_plot: a boolean variable to determine whether to show plot of new prediction obtained after applying inpainting technique(default, True)\n",
    "        '''\n",
    "        for ind in range(self.adv_images.shape[0]):\n",
    "\n",
    "            inpaint_img = (self.adv_images[ind]).copy()\n",
    "\n",
    "            src_img = inpaint_img\n",
    "            img = inpaint_img\n",
    "            mask = self.patch_masks[ind]\n",
    "\n",
    "            inpaint_img = inpaint(src_img, img, mask)\n",
    "\n",
    "            self.inpaint_images.append(inpaint_img)\n",
    "\n",
    "            inpaint_img = np.expand_dims(inpaint_img.copy(), axis=0)\n",
    "\n",
    "            preprocess_fn = self.preprocess_input_fn()\n",
    "            decode_fn = self.decode_predictionst_fn()\n",
    "                    \n",
    "            # Find new predictions after inpainting\n",
    "            tmp_img = preprocess_fn(inpaint_img.copy())\n",
    "            img_pred = self.model.predict(tmp_img)\n",
    "            prediction = decode_fn(img_pred, top=1)\n",
    "            class_lbl = self.classlabel.index(prediction[0][0][1])\n",
    "\n",
    "            self.new_predictions.append(prediction[0][0])\n",
    "            self.new_class_lbls.append(class_lbl)\n",
    "\n",
    "            if show_plot == True:\n",
    "                self.plot_images(inpaint_img)\n",
    "\n",
    "        # Convert all the list to array elements\n",
    "        self.inpaint_images = cnv_lst_arr(self.inpaint_images)\n",
    "        self.new_predictions = cnv_lst_arr(self.new_predictions)\n",
    "        self.new_class_lbls = cnv_lst_arr(self.new_class_lbls)\n",
    "\n",
    "\n",
    "    def plot_images(self, img):\n",
    "        '''\n",
    "        Plot the image with title as the prediction class, confidence and its class label.\n",
    "\n",
    "        Args:\n",
    "            img: The imaeg to be plotted [1, 224, 224, 3]\n",
    "        '''\n",
    "         # Find new predictions after inpainting\n",
    "        tmp_img = preprocess_input(img.copy())\n",
    "        img_pred = self.model.predict(tmp_img)\n",
    "        prediction = decode_predictions(img_pred, top=1)\n",
    "        class_lbl = self.classlabel.index(prediction[0][0][1])\n",
    "\n",
    "        # Rendering\n",
    "        plt.figure(figsize=(3, 4))\n",
    "        plt.title(f'Prediction: {prediction[0][0][1]}({prediction[0][0][2]:1.3})\\nLabel: {class_lbl}')\n",
    "        plt.imshow(np.uint8(img[0]))\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def generate_inpaint(self, step=10, grad_flag=False, mask_flag=False, inpaint_flag=False):\n",
    "        '''\n",
    "        A function that performs the given tasks in sequential order. \n",
    "\n",
    "        Args:\n",
    "            grad_plot: Indicates if we want to display the plot of gradient cam\n",
    "            mask_flag: Indicates if we want to display the plot of mask obtained\n",
    "            inpaint_flag: Indicates if we want to display the plot of inapint images\n",
    "        '''\n",
    "        for mini_batch in range(0, self.batch_size, step):            \n",
    "            # After loading od data is done, generate its saliency map using grad CAM technique\n",
    "            self.apply_cam(mini_batch, mini_batch+step, show_plot=grad_flag)\n",
    "        self.cams = cnv_lst_arr(self.cams)\n",
    "        \n",
    "        # genearate a mask by setting a threshold value \n",
    "        self.gen_mask(show_plot=mask_flag)\n",
    "\n",
    "        # Apply inpainting technique and get predictions for class\n",
    "        self.apply_inpaint(show_plot=inpaint_flag)\n",
    "\n",
    "    def plot_data(self, index):\n",
    "        '''\n",
    "        Plots the graph of following:\n",
    "            1. Original image\n",
    "            2. Its heatmap generated using Scorecam\n",
    "            3. The binary mask generated from the heatmap\n",
    "            4. The final image after applying inpainting technique\n",
    "\n",
    "        Args:\n",
    "            index: The index of the image to print the plots\n",
    "        '''\n",
    "        if index < self.batch_size-1:\n",
    "            fig, axes = plt.subplots(1, 5, figsize=(12, 7))\n",
    "            fig.tight_layout()\n",
    "\n",
    "            axes[0].imshow(self.clean_images[index])\n",
    "            axes[0].set_title(f'Clean Prediction\\n{self.clean_predictions[index][1]}({self.clean_predictions[index][2].astype(np.float32):1.3f})\\nLabel: {self.clean_class_lbls[index]}')\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            axes[1].imshow(self.adv_images[index])\n",
    "            axes[1].set_title(f'Adv Prediction\\n{self.adv_predictions[index][1]}({self.adv_predictions[index][2].astype(np.float32):1.3f})\\nLabel: {self.adv_class_lbls[index]}')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            axes[2].imshow(self.cams[index])\n",
    "            axes[2].set_title('Heatmap of\\nsalient feature')\n",
    "            axes[2].axis('off')\n",
    "\n",
    "            axes[3].imshow(self.patch_masks[index], cmap='gray')\n",
    "            axes[3].set_title('Binary mask\\nfor inpainting')\n",
    "            axes[3].axis('off')\n",
    "\n",
    "            axes[4].imshow(self.inpaint_images[index])\n",
    "            axes[4].set_title(f'Inpaint Prediction\\n{self.new_predictions[index][1]}({self.new_predictions[index][2].astype(np.float32):1.3f})\\nLabel: {self.new_class_lbls[index]}')\n",
    "            axes[4].axis('off')\n",
    "\n",
    "    def defense_accuracy(self):\n",
    "        '''\n",
    "        Calculate the following accuracies:\n",
    "            1. Clean accuracy of the model\n",
    "            2. Misclassification accuracy of the patch\n",
    "            3. Inpainting accuracy after applying diffusion technique\n",
    "        '''\n",
    "        correct_clean = 0\n",
    "        correct_adv = 0\n",
    "        correct_new = 0\n",
    "        n_success = 0\n",
    "        n_samples = self.batch_size\n",
    "        filename = f\"output_{self.activ_fn.__name__}.txt\"\n",
    "\n",
    "        if n_samples != 0:\n",
    "            for index in range(self.batch_size):\n",
    "                correct_clean += self.ground_truths[index] == self.clean_predictions[:, 1][index]\n",
    "\n",
    "                correct_adv += self.ground_truths[index] == self.adv_predictions[:, 1][index]\n",
    "\n",
    "                correct_new += self.ground_truths[index] == self.new_predictions[:, 1][index]\n",
    "\n",
    "            clean_accuracy = 100 * (correct_clean / n_samples)\n",
    "            misclassification_accuracy = 100 * (1 - correct_adv / n_samples)\n",
    "            inpaint_accuracy = 100*(correct_new / n_samples)\n",
    "\n",
    "            print(f'Clean accuracy: {clean_accuracy:>0.2f}%')\n",
    "            print(f'Patch success accuracy: {misclassification_accuracy:>0.2f}%')\n",
    "            print(f'Inpainting Accuracy: {inpaint_accuracy:>0.2f}%')\n",
    "            \n",
    "            with open(filename, 'w')as f:\n",
    "                f.write(f'batch size: {self.batch_size}\\n')\n",
    "                f.write(f'Clean accuracy: {clean_accuracy:>0.2f}%\\n')\n",
    "                f.write(f'Patch success accuracy: {misclassification_accuracy:>0.2f}%\\n')\n",
    "                f.write(f'Inpainting Accuracy: {inpaint_accuracy:>0.2f}%\\n')\n",
    "        else:\n",
    "            print('There are no samples in the dataset to calculate the accuracy')\n",
    "            with open(filename, 'w') as f:\n",
    "                f.write('There are no samples in the dataset to calculate the accuracy.\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_torch_env",
   "language": "python",
   "name": "tf_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
